{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teknologi mixed reality akan membuat interaksi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>penjadwalan merupakan salah satu proses pentin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>untuk memenuhi kebutuhan masyarakat akan keter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perusahaan mcdonald’s adalah perusahaan yang b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perkembangan internet saat ini sangat pesat. d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract\n",
       "0  teknologi mixed reality akan membuat interaksi...\n",
       "1  penjadwalan merupakan salah satu proses pentin...\n",
       "2  untuk memenuhi kebutuhan masyarakat akan keter...\n",
       "3  perusahaan mcdonald’s adalah perusahaan yang b...\n",
       "4  perkembangan internet saat ini sangat pesat. d..."
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/keyword_jptiik.csv\")\n",
    "\n",
    "data_abs = data[[\"abstract\"]]\n",
    "data_abs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.strip()\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.lower()\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.replace('[^\\w\\s]','')\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.replace('\\d+', '')\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.replace('\\s+', ' ')\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.replace('\\n', ' ')\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.replace('\\t', ' ')\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = StopWordRemoverFactory().create_stop_word_remover()\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: stopword.remove(x))\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "max_tokens = 10000\n",
    "\n",
    "for abstract in data_abs[\"abstract\"]:\n",
    "    for word in abstract.split():\n",
    "        vocab.add(word)\n",
    "    \n",
    "vocab = list(vocab)\n",
    "random.shuffle(vocab)\n",
    "vocab = vocab[:max_tokens]\n",
    "vocab += [\"<UNK>\"]\n",
    "\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: x.split())\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: [word if word in vocab else \"<UNK>\" for word in x])\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: [word2idx[word] for word in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean length of abstract\n",
    "MAX_LENGTH = round(sum([len(abstract) for abstract in data_abs[\"abstract\"]]) / len(data_abs[\"abstract\"]))\n",
    "\n",
    "# padding and truncate\n",
    "data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: x + [0] * (MAX_LENGTH - len(x)) if len(x) < MAX_LENGTH else x[:MAX_LENGTH])\n",
    "# data_abs[\"abstract\"] = data_abs[\"abstract\"].apply(lambda x: torch.tensor(x).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, 512)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.gelu = nn.GELU()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc3 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc1 = nn.Linear(256, 512)\n",
    "        self.embedding = nn.Embedding(512, VOCAB_SIZE)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.selu = nn.SELU()\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.tensor(x).long()\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         ...,\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446]],\n",
       "\n",
       "        [[ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         ...,\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446]],\n",
       "\n",
       "        [[ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         ...,\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         ...,\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446]],\n",
       "\n",
       "        [[ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         ...,\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446]],\n",
       "\n",
       "        [[ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         ...,\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446],\n",
       "         [ 1.6013,  0.6687, -1.2794,  ..., -1.6663, -1.9133,  0.1446]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = Encoder()\n",
    "D = Decoder()\n",
    "\n",
    "forward = E(torch.tensor(data_abs[\"abstract\"][0]).type(torch.LongTensor))\n",
    "D(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10001) must match the size of tensor b (109) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Project\\Road To Data Science\\Research\\Latent-dim Clustering via AE\\notebooks\\poc.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Project/Road%20To%20Data%20Science/Research/Latent-dim%20Clustering%20via%20AE/notebooks/poc.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Project/Road%20To%20Data%20Science/Research/Latent-dim%20Clustering%20via%20AE/notebooks/poc.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(AE\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Project/Road%20To%20Data%20Science/Research/Latent-dim%20Clustering%20via%20AE/notebooks/poc.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m criterion(forward, torch\u001b[39m.\u001b[39;49mtensor(data_abs[\u001b[39m\"\u001b[39;49m\u001b[39mabstract\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39;49mlong())\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\functional.py:3291\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3288\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3289\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3291\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3292\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10001) must match the size of tensor b (109) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "E = Encoder()\n",
    "D = Decoder()\n",
    "AE = AutoEncoder(E, D)\n",
    "forward = AE(torch.tensor(data_abs[\"abstract\"][0]).type(torch.LongTensor))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(AE.parameters(), lr=1e-3)\n",
    "\n",
    "criterion(forward, torch.tensor(data_abs[\"abstract\"][0]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6918.1338, grad_fn=<SqrtBackward0>)\n",
      "tensor(6918.1338, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Project\\Road To Data Science\\Research\\Latent-dim Clustering via AE\\notebooks\\poc.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Project/Road%20To%20Data%20Science/Research/Latent-dim%20Clustering%20via%20AE/notebooks/poc.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(criterion(output, abstract))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Project/Road%20To%20Data%20Science/Research/Latent-dim%20Clustering%20via%20AE/notebooks/poc.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/Project/Road%20To%20Data%20Science/Research/Latent-dim%20Clustering%20via%20AE/notebooks/poc.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Project/Road%20To%20Data%20Science/Research/Latent-dim%20Clustering%20via%20AE/notebooks/poc.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(loss)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    235\u001b[0m          grads,\n\u001b[0;32m    236\u001b[0m          exp_avgs,\n\u001b[0;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    239\u001b[0m          state_steps,\n\u001b[0;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[0;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m func(params,\n\u001b[0;32m    301\u001b[0m      grads,\n\u001b[0;32m    302\u001b[0m      exp_avgs,\n\u001b[0;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    305\u001b[0m      state_steps,\n\u001b[0;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\DataScience\\lib\\site-packages\\torch\\optim\\adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    360\u001b[0m     param \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(param)\n\u001b[0;32m    362\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m    364\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "E = Encoder(109, 64, 32, 16)\n",
    "D = Decoder(109, 64, 32, 16)\n",
    "AE = AutoEncoder(E, D)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(AE.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for abstract in data_abs[\"abstract\"]:\n",
    "    # abstract = torch.tensor(data_abs[\"abstract\"][0], dtype=torch.float32)\n",
    "        abstract = torch.tensor(abstract, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = AE(abstract)\n",
    "        loss = torch.sqrt(criterion(output, abstract))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Aug 18 2021, 15:44:49) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3120404ab40088dde46363bad1bdd78d1aeca7b6f18e79999fc72cb3d9151a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
